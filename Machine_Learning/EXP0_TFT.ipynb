{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_forecasting.metrics import QuantileLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = pd.read_csv('D:/MAC-Course/Sem 2/ADT/Final Project/Predicting_Canadian_Job_Vacancies-main/Predicting_Canadian_Job_Vacancies-main/Database/Resources/MachineLearning.csv')\n",
    "data['ref_date'] = pd.to_datetime(data['ref_date'], format='%m-%d-%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data by date, geo, and sector\n",
    "aggregated_data = (\n",
    "    data.groupby(['ref_date', 'geo', 'noc_desc', 'job_char'], as_index=False)\n",
    "    .agg({'total_vacancies': 'sum'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale total_vacancies\n",
    "scaler = MinMaxScaler()\n",
    "aggregated_data['total_vacancies_scaled'] = scaler.fit_transform(\n",
    "    aggregated_data[['total_vacancies']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in categorical columns before encoding\n",
    "aggregated_data['geo'] = aggregated_data['geo'].fillna('unknown')  # Replace NaNs with 'unknown'\n",
    "aggregated_data['noc_desc'] = aggregated_data['noc_desc'].fillna('unknown')  # Replace NaNs with 'unknown'\n",
    "aggregated_data['job_char'] = aggregated_data['job_char'].fillna('unknown')  # Replace NaNs with 'unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize encoders\n",
    "geo_encoder = NaNLabelEncoder()\n",
    "sector_encoder = NaNLabelEncoder()\n",
    "job_char_encoder = NaNLabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "aggregated_data['geo_encoded'] = geo_encoder.fit_transform(aggregated_data['geo'])\n",
    "aggregated_data['noc_desc_encoded'] = sector_encoder.fit_transform(aggregated_data['noc_desc'])\n",
    "aggregated_data['job_char_encoded'] = job_char_encoder.fit_transform(aggregated_data['job_char'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time index\n",
    "aggregated_data['time_idx'] = (aggregated_data['ref_date'] - aggregated_data['ref_date'].min()).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fill missing time steps\n",
    "\n",
    "# Expand time index for continuity\n",
    "full_range = (\n",
    "    aggregated_data.groupby(['geo_encoded', 'noc_desc_encoded', 'job_char_encoded'])['time_idx']\n",
    "    .apply(lambda x: pd.RangeIndex(start=x.min(), stop=x.max() + 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_18676\\699740459.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  expanded_data.ffill(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with all combinations of groups and time_idx\n",
    "expanded_data = (\n",
    "    full_range.reset_index()\n",
    "    .explode('time_idx')\n",
    "    .merge(aggregated_data, on=['geo_encoded', 'noc_desc_encoded', 'job_char_encoded' ,'time_idx'], how='left')\n",
    ")\n",
    "expanded_data.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 3: Check the differences between consecutive time_idx to ensure continuity\n",
    "# print(expanded_data.groupby(['geo_encoded', 'noc_desc_encoded'])['time_idx'].diff().unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TimeSeriesDataSet\n",
    "max_encoder_length = 30\n",
    "max_prediction_length = 60  \n",
    "\n",
    "# Filter valid groups\n",
    "group_counts = expanded_data.groupby([\"geo_encoded\", \"noc_desc_encoded\", 'job_char_encoded']).size()\n",
    "min_required_length = max_encoder_length + max_prediction_length\n",
    "valid_groups = group_counts[group_counts >= min_required_length].index\n",
    "\n",
    "expanded_data = expanded_data[\n",
    "    expanded_data.set_index([\"geo_encoded\", \"noc_desc_encoded\", 'job_char_encoded']).index.isin(valid_groups)\n",
    "]\n",
    "\n",
    "train_df, val_df = train_test_split(expanded_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_encoded</th>\n",
       "      <th>noc_desc_encoded</th>\n",
       "      <th>job_char_encoded</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>ref_date</th>\n",
       "      <th>geo</th>\n",
       "      <th>noc_desc</th>\n",
       "      <th>job_char</th>\n",
       "      <th>total_vacancies</th>\n",
       "      <th>total_vacancies_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195316</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2081</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Trades, transport and equipment operators and ...</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>0.002180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187874</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>229</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Total, all occupations</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846699</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Total, all occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>95165.0</td>\n",
       "      <td>0.092195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204594</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1495</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>8125.0</td>\n",
       "      <td>0.007871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030612</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2588</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Trades, transport and equipment operators and ...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>31775.0</td>\n",
       "      <td>0.030783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110270</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2141</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Health occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4905.0</td>\n",
       "      <td>0.004752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259181</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1647</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Occupations in education, law and social, comm...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>20570.0</td>\n",
       "      <td>0.019928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131934</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>798</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Natural and applied sciences and related occup...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>0.004108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671197</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1616</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>Occupations in education, law and social, comm...</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>485.0</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121960</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1415</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Legislative and senior management occupations</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>959726 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geo_encoded  noc_desc_encoded  job_char_encoded  time_idx   ref_date  \\\n",
       "195316             1                10                 1      2081 2020-01-10   \n",
       "1187874           13                 9                 2       229 2015-01-10   \n",
       "846699             9                 9                 0       241 2015-01-10   \n",
       "204594             2                 0                 1      1495 2019-01-10   \n",
       "1030612           11                10                 0      2588 2022-01-10   \n",
       "...              ...               ...               ...       ...        ...   \n",
       "110270             1                 1                 0      2141 2020-01-10   \n",
       "259181             2                 6                 0      1647 2019-01-10   \n",
       "131934             1                 3                 2       798 2017-01-10   \n",
       "671197             7                 6                 1      1616 2019-01-10   \n",
       "121960             1                 2                 1      1415 2018-01-10   \n",
       "\n",
       "                      geo                                           noc_desc  \\\n",
       "195316   British Columbia  Trades, transport and equipment operators and ...   \n",
       "1187874             Yukon                             Total, all occupations   \n",
       "846699            Ontario                             Total, all occupations   \n",
       "204594             Canada   Business, finance and administration occupations   \n",
       "1030612            Quebec  Trades, transport and equipment operators and ...   \n",
       "...                   ...                                                ...   \n",
       "110270   British Columbia                                 Health occupations   \n",
       "259181             Canada  Occupations in education, law and social, comm...   \n",
       "131934   British Columbia  Natural and applied sciences and related occup...   \n",
       "671197        Nova Scotia  Occupations in education, law and social, comm...   \n",
       "121960   British Columbia      Legislative and senior management occupations   \n",
       "\n",
       "                        job_char  total_vacancies  total_vacancies_scaled  \n",
       "195316                 Part-time           2250.0                0.002180  \n",
       "1187874  Type of work, all types            465.0                0.000450  \n",
       "846699                 Full-time          95165.0                0.092195  \n",
       "204594                 Part-time           8125.0                0.007871  \n",
       "1030612                Full-time          31775.0                0.030783  \n",
       "...                          ...              ...                     ...  \n",
       "110270                 Full-time           4905.0                0.004752  \n",
       "259181                 Full-time          20570.0                0.019928  \n",
       "131934   Type of work, all types           4240.0                0.004108  \n",
       "671197                 Part-time            485.0                0.000470  \n",
       "121960                 Part-time              5.0                0.000005  \n",
       "\n",
       "[959726 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset: 327863\n",
      "train_loader: 17131\n",
      "val_loader: 5123\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"total_vacancies_scaled\",\n",
    "    group_ids=[\"geo_encoded\", \"noc_desc_encoded\", 'job_char_encoded'],\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_unknown_reals=[\"total_vacancies_scaled\"],\n",
    "    categorical_encoders={\n",
    "        \"geo_encoded\": NaNLabelEncoder(),\n",
    "        \"noc_desc_encoded\": NaNLabelEncoder(),\n",
    "        'job_char_encoded': NaNLabelEncoder()\n",
    "    },\n",
    "    target_normalizer=GroupNormalizer(groups=[\"geo_encoded\", \"noc_desc_encoded\", 'job_char_encoded']),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "val_dataset = TimeSeriesDataSet.from_dataset(train_dataset, val_df, stop_randomization=True)\n",
    "\n",
    "train_loader = train_dataset.to_dataloader(train=True, batch_size=64, shuffle=True)\n",
    "val_loader = val_dataset.to_dataloader(train=False, batch_size=64)\n",
    "\n",
    "\n",
    "# Step 4: Verify that the dataset is correctly formatted\n",
    "print(f\"Number of samples in dataset: {len(val_dataset)}\")\n",
    "print(f\"train_loader: {len(train_loader)}\")\n",
    "print(f\"val_loader: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid groups after filtering: 392\n",
      "         geo_encoded  noc_desc_encoded  job_char_encoded\n",
      "0                  0                 0                 0\n",
      "3288               0                 0                 1\n",
      "6576               0                 0                 2\n",
      "9864               0                 1                 0\n",
      "13152              0                 1                 1\n",
      "...              ...               ...               ...\n",
      "1184360           13                 9                 1\n",
      "1187648           13                 9                 2\n",
      "1190936           13                10                 0\n",
      "1193862           13                10                 1\n",
      "1196420           13                10                 2\n",
      "\n",
      "[392 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valid groups after filtering: {len(valid_groups)}\")\n",
    "print(expanded_data[['geo_encoded', 'noc_desc_encoded', 'job_char_encoded']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_encoded</th>\n",
       "      <th>noc_desc_encoded</th>\n",
       "      <th>job_char_encoded</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>ref_date</th>\n",
       "      <th>geo</th>\n",
       "      <th>noc_desc</th>\n",
       "      <th>job_char</th>\n",
       "      <th>total_vacancies</th>\n",
       "      <th>total_vacancies_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>0.004558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>0.004558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>0.004558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>0.004127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>0.004127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199703</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3286</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Trades, transport and equipment operators and ...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199704</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3287</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Trades, transport and equipment operators and ...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199705</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3288</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Trades, transport and equipment operators and ...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199706</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3289</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Trades, transport and equipment operators and ...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199707</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3290</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Trades, transport and equipment operators and ...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199658 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geo_encoded  noc_desc_encoded  job_char_encoded  time_idx   ref_date  \\\n",
       "0                  0                 0                 0         3 2015-01-04   \n",
       "1                  0                 0                 0         4 2015-01-04   \n",
       "2                  0                 0                 0         5 2015-01-04   \n",
       "3                  0                 0                 0         6 2015-01-07   \n",
       "4                  0                 0                 0         7 2015-01-07   \n",
       "...              ...               ...               ...       ...        ...   \n",
       "1199703           13                10                 2      3286 2023-01-10   \n",
       "1199704           13                10                 2      3287 2024-01-01   \n",
       "1199705           13                10                 2      3288 2024-01-01   \n",
       "1199706           13                10                 2      3289 2024-01-01   \n",
       "1199707           13                10                 2      3290 2024-01-04   \n",
       "\n",
       "             geo                                           noc_desc  \\\n",
       "0        Alberta   Business, finance and administration occupations   \n",
       "1        Alberta   Business, finance and administration occupations   \n",
       "2        Alberta   Business, finance and administration occupations   \n",
       "3        Alberta   Business, finance and administration occupations   \n",
       "4        Alberta   Business, finance and administration occupations   \n",
       "...          ...                                                ...   \n",
       "1199703    Yukon  Trades, transport and equipment operators and ...   \n",
       "1199704    Yukon  Trades, transport and equipment operators and ...   \n",
       "1199705    Yukon  Trades, transport and equipment operators and ...   \n",
       "1199706    Yukon  Trades, transport and equipment operators and ...   \n",
       "1199707    Yukon  Trades, transport and equipment operators and ...   \n",
       "\n",
       "                        job_char  total_vacancies  total_vacancies_scaled  \n",
       "0                      Full-time           4705.0                0.004558  \n",
       "1                      Full-time           4705.0                0.004558  \n",
       "2                      Full-time           4705.0                0.004558  \n",
       "3                      Full-time           4260.0                0.004127  \n",
       "4                      Full-time           4260.0                0.004127  \n",
       "...                          ...              ...                     ...  \n",
       "1199703  Type of work, all types            240.0                0.000233  \n",
       "1199704  Type of work, all types            165.0                0.000160  \n",
       "1199705  Type of work, all types            165.0                0.000160  \n",
       "1199706  Type of work, all types            165.0                0.000160  \n",
       "1199707  Type of work, all types            185.0                0.000179  \n",
       "\n",
       "[1199658 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Assuming 'expanded_data' is your preprocessed DataFrame\n",
    "# train_df, val_df = train_test_split(expanded_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TimeSeriesDataSet(\n",
    "#     train_df,\n",
    "#     time_idx=\"time_idx\",\n",
    "#     target=\"total_vacancies_scaled\",\n",
    "#     group_ids=[\"geo_encoded\", \"noc_desc_encoded\"],\n",
    "#     min_encoder_length=max_encoder_length // 2,\n",
    "#     max_encoder_length=max_encoder_length,\n",
    "#     min_prediction_length=1,\n",
    "#     max_prediction_length=max_prediction_length,\n",
    "#     time_varying_unknown_reals=[\"total_vacancies_scaled\"],\n",
    "#     categorical_encoders={\n",
    "#         \"geo_encoded\": NaNLabelEncoder(),\n",
    "#         \"noc_desc_encoded\": NaNLabelEncoder(),\n",
    "#     },\n",
    "#     target_normalizer=GroupNormalizer(\n",
    "#         groups=[\"geo_encoded\", \"noc_desc_encoded\"], transformation=\"softplus\"\n",
    "#     ),\n",
    "#     add_relative_time_idx=True,\n",
    "#     add_target_scales=True,\n",
    "#     add_encoder_length=True,\n",
    "#     allow_missing_timesteps=True,  # Added this line\n",
    "# )\n",
    "\n",
    "\n",
    "# val_dataset = TimeSeriesDataSet(\n",
    "#     val_df,\n",
    "#     time_idx=\"time_idx\",\n",
    "#     target=\"total_vacancies_scaled\",\n",
    "#     group_ids=[\"geo_encoded\", \"noc_desc_encoded\"],\n",
    "#     min_encoder_length=max_encoder_length // 2,\n",
    "#     max_encoder_length=max_encoder_length,\n",
    "#     min_prediction_length=1,\n",
    "#     max_prediction_length=max_prediction_length,\n",
    "#     time_varying_unknown_reals=[\"total_vacancies_scaled\"],\n",
    "#     categorical_encoders={\n",
    "#         \"geo_encoded\": NaNLabelEncoder(),\n",
    "#         \"noc_desc_encoded\": NaNLabelEncoder(),\n",
    "#     },\n",
    "#     target_normalizer=GroupNormalizer(\n",
    "#         groups=[\"geo_encoded\", \"noc_desc_encoded\"], transformation=\"softplus\"\n",
    "#     ),\n",
    "#     add_relative_time_idx=True,\n",
    "#     add_target_scales=True,\n",
    "#     add_encoder_length=True,\n",
    "#     allow_missing_timesteps=True,  # Fix applied here as well\n",
    "\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create DataLoaders from the TimeSeriesDataSet\n",
    "# batch_size = 64\n",
    "# train_loader = train_dataset.to_dataloader(train=True, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = val_dataset.to_dataloader(train=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\__init__.py:171: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n",
      "  super().__init__(loss=loss, logging_metrics=logging_metrics, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define and train Temporal Fusion Transformer\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # QuantileLoss output size\n",
    "    loss=QuantileLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'encoder_cat': tensor([], size=(1, 30, 0), dtype=torch.int64), 'encoder_cont': tensor([[[ 1.0000, -0.2729, -0.2814, -1.0000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.9667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.9333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.9000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.8667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.8333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.8000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.7667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.7333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.7000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.6667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.6333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.6000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.5667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.5333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.5000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.4667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.4333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.4000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.3667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.3333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.3000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.2667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.2333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.2000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.1667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.1333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.1000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.0667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814, -0.0333,  0.3095]]]), 'encoder_target': tensor([[0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008]]), 'encoder_lengths': tensor([30]), 'decoder_cat': tensor([], size=(1, 60, 0), dtype=torch.int64), 'decoder_cont': tensor([[[ 1.0000, -0.2729, -0.2814,  0.0000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.0333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.0667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.1000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.1333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.1667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.2000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.2333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.2667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.3000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.3333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.3667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.4000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.4333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.4667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.5000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.5333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.5667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.6000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.6333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.6667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.7000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.7333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.7667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.8000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.8333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.8667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.9000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.9333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  0.9667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.0000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.0333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.0667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.1000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.1333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.1667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.2000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.2333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.2667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.3000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.3333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.3667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.4000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.4333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.4667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.5000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.5333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.5667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.6000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.6333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.6667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.7000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.7333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.7667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.8000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.8333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.8667,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.9000,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.9333,  0.3095],\n",
      "         [ 1.0000, -0.2729, -0.2814,  1.9667,  0.3095]]]), 'decoder_target': tensor([[0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008]]), 'decoder_lengths': tensor([60]), 'decoder_time_idx': tensor([[3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048,\n",
      "         3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060,\n",
      "         3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072,\n",
      "         3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084,\n",
      "         3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096]]), 'groups': tensor([[5, 1, 1]]), 'target_scale': tensor([[0.0004, 0.0011]])}, (tensor([[0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "         0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008]]), None))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Convert dataset to a DataLoader\n",
    "dataloader = train_dataset.to_dataloader(train=True, batch_size=1)\n",
    "\n",
    "# Fetch one batch\n",
    "batch = next(iter(dataloader))\n",
    "print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   geo_encoded  noc_desc_encoded  job_char_encoded  time_idx   ref_date  \\\n",
      "0            0                 0                 0         3 2015-01-04   \n",
      "1            0                 0                 0         4 2015-01-04   \n",
      "2            0                 0                 0         5 2015-01-04   \n",
      "3            0                 0                 0         6 2015-01-07   \n",
      "4            0                 0                 0         7 2015-01-07   \n",
      "\n",
      "       geo                                          noc_desc   job_char  \\\n",
      "0  Alberta  Business, finance and administration occupations  Full-time   \n",
      "1  Alberta  Business, finance and administration occupations  Full-time   \n",
      "2  Alberta  Business, finance and administration occupations  Full-time   \n",
      "3  Alberta  Business, finance and administration occupations  Full-time   \n",
      "4  Alberta  Business, finance and administration occupations  Full-time   \n",
      "\n",
      "   total_vacancies  total_vacancies_scaled  \n",
      "0           4705.0                0.004558  \n",
      "1           4705.0                0.004558  \n",
      "2           4705.0                0.004558  \n",
      "3           4260.0                0.004127  \n",
      "4           4260.0                0.004127  \n"
     ]
    }
   ],
   "source": [
    "print(expanded_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "Inputs: {'encoder_cat': tensor([], size=(1, 30, 0), dtype=torch.int64), 'encoder_cont': tensor([[[ 1.0000,  0.1779,  0.1379, -1.0000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.9667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.9333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.9000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.8667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.8333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.8000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.7667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.7333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.7000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.6667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.6333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.6000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.5667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.5333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.5000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.4667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.4333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.4000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.3667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.3333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.3000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.2667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.2333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.2000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.1667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.1333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.1000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.0667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379, -0.0333, -0.5930]]]), 'encoder_target': tensor([[0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160]]), 'encoder_lengths': tensor([30]), 'decoder_cat': tensor([], size=(1, 60, 0), dtype=torch.int64), 'decoder_cont': tensor([[[ 1.0000,  0.1779,  0.1379,  0.0000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.0333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.0667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.1000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.1333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.1667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.2000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.2333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.2667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.3000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.3333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.3667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.4000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.4333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.4667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.5000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.5333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.5667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.6000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.6333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.6667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.7000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.7333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.7667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.8000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.8333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.8667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.9000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.9333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  0.9667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.0000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.0333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.0667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.1000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.1333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.1667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.2000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.2333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.2667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.3000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.3333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.3667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.4000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.4333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.4667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.5000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.5333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.5667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.6000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.6333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.6667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.7000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.7333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.7667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.8000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.8333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.8667, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.9000, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.9333, -0.5930],\n",
      "         [ 1.0000,  0.1779,  0.1379,  1.9667, -0.5930]]]), 'decoder_target': tensor([[0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160]]), 'decoder_lengths': tensor([60]), 'decoder_time_idx': tensor([[2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142,\n",
      "         2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154,\n",
      "         2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162, 2163, 2164, 2165, 2166,\n",
      "         2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178,\n",
      "         2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190]]), 'groups': tensor([[1, 8, 0]]), 'target_scale': tensor([[0.0202, 0.0071]])}\n",
      "Targets: (tensor([[0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160]]), None)\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(dataloader):\n",
    "    x, y = batch\n",
    "    print(f\"Batch {idx}:\")\n",
    "    print(\"Inputs:\", x)\n",
    "    print(\"Targets:\", y)\n",
    "    break  # Only check the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoder_length', 'total_vacancies_scaled_center', 'total_vacancies_scaled_scale', 'relative_time_idx', 'total_vacancies_scaled']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.reals)\n",
    "print(train_dataset.categoricals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.199658e+06\n",
      "mean     1.236873e-02\n",
      "std      4.617354e-02\n",
      "min      0.000000e+00\n",
      "25%      1.986020e-04\n",
      "50%      1.036606e-03\n",
      "75%      5.928997e-03\n",
      "max      1.000000e+00\n",
      "Name: total_vacancies_scaled, dtype: float64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(expanded_data['total_vacancies_scaled'].describe())\n",
    "print(expanded_data['total_vacancies_scaled'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x21961c407a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_data[\"geo_encoded\"] = expanded_data[\"geo_encoded\"].astype(str)\n",
    "expanded_data[\"noc_desc_encoded\"] = expanded_data[\"noc_desc_encoded\"].astype(str)\n",
    "expanded_data[\"job_char_encoded\"] = expanded_data[\"job_char_encoded\"].astype(str)\n",
    "expanded_data[\"total_vacancies_scaled\"] = expanded_data[\"total_vacancies_scaled\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_encoded  noc_desc_encoded  job_char_encoded\n",
      "0            0                 0                   3288\n",
      "                               1                   3288\n",
      "                               2                   3288\n",
      "             1                 0                   3288\n",
      "                               1                   3288\n",
      "                                                   ... \n",
      "9            8                 1                   3288\n",
      "                               2                   3288\n",
      "             9                 0                   3288\n",
      "                               1                   3288\n",
      "                               2                   3288\n",
      "Length: 392, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "group_counts = expanded_data.groupby([\"geo_encoded\", \"noc_desc_encoded\", 'job_char_encoded']).size()\n",
    "print(group_counts[group_counts >= (max_encoder_length + max_prediction_length)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type                      | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | tft  | TemporalFusionTransformer | 17.6 K | train\n",
      "-----------------------------------------------------------\n",
      "17.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.6 K    Total params\n",
      "0.070     Total estimated model params size (MB)\n",
      "230       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 37/17131 [00:19<2:32:29,  1.87it/s, v_num=109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    570\u001b[0m     ckpt_path,\n\u001b[0;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 250\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1306\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1304\u001b[0m \n\u001b[0;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1306\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:122\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:202\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 202\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:108\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:138\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:239\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[1;34m(loss)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward_fn\u001b[39m(loss: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:212\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[1;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:72\u001b[0m, in \u001b[0;36mPrecision.backward\u001b[1;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1101\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[1;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1101\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m early_stop_callback \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[early_stop_callback])\n\u001b[1;32m---> 40\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtft_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "class TFTModule(LightningModule):\n",
    "\tdef __init__(self, tft):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.tft = tft\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\ty_pred = self.tft(x)\n",
    "\t\t# Ensure y_pred has the correct shape\n",
    "\t\tif isinstance(y_pred, tuple):\n",
    "\t\t\ty_pred = y_pred[0]\n",
    "\t\treturn y_pred\n",
    "\n",
    "\tdef training_step(self, batch, batch_idx):\n",
    "\t\tx, y = batch\n",
    "\t\ty_hat = self(x)\n",
    "\t\tloss = self.tft.loss(y_hat, y)\n",
    "\t\tself.log(\"train_loss\", loss)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef validation_step(self, batch, batch_idx):\n",
    "\t\tx, y = batch\n",
    "\t\ty_hat = self(x)\n",
    "\t\tloss = self.tft.loss(y_hat, y)\n",
    "\t\tself.log(\"val_loss\", loss)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef configure_optimizers(self):\n",
    "\t\treturn torch.optim.Adam(self.parameters(), lr=0.03)\n",
    "\n",
    "tft_module = TFTModule(tft)\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=True, mode=\"min\")\n",
    "trainer = Trainer(max_epochs=1, accelerator=\"auto\", callbacks=[early_stop_callback])\n",
    "\n",
    "trainer.fit(tft_module, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# torch.save(tft_module.state_dict(), \"tft_model_job_char.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_18676\\2421508201.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tft_module.load_state_dict(torch.load(\"tft_model_job_char.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TFTModule(\n",
       "  (tft): TemporalFusionTransformer(\n",
       "    \t\"attention_head_size\":               1\n",
       "    \t\"categorical_groups\":                {}\n",
       "    \t\"causal_attention\":                  True\n",
       "    \t\"dataset_parameters\":                {'time_idx': 'time_idx', 'target': 'total_vacancies_scaled', 'group_ids': ['geo_encoded', 'noc_desc_encoded', 'job_char_encoded'], 'weight': None, 'max_encoder_length': 30, 'min_encoder_length': 15, 'min_prediction_idx': 0, 'min_prediction_length': 60, 'max_prediction_length': 60, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': None, 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['total_vacancies_scaled'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': True, 'lags': None, 'add_relative_time_idx': True, 'add_target_scales': True, 'add_encoder_length': True, 'target_normalizer': GroupNormalizer(\n",
       "    \t\tmethod='standard',\n",
       "    \t\tgroups=['geo_encoded', 'noc_desc_encoded', 'job_char_encoded'],\n",
       "    \t\tcenter=True,\n",
       "    \t\tscale_by_group=False,\n",
       "    \t\ttransformation=None,\n",
       "    \t\tmethod_kwargs={}\n",
       "    \t), 'categorical_encoders': {'geo_encoded': NaNLabelEncoder(add_nan=False, warn=True), 'noc_desc_encoded': NaNLabelEncoder(add_nan=False, warn=True), 'job_char_encoded': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__geo_encoded': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__noc_desc_encoded': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__job_char_encoded': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {'encoder_length': StandardScaler(), 'total_vacancies_scaled_center': StandardScaler(), 'total_vacancies_scaled_scale': StandardScaler(), 'relative_time_idx': StandardScaler()}, 'randomize_length': None, 'predict_mode': False}\n",
       "    \t\"dropout\":                           0.1\n",
       "    \t\"embedding_labels\":                  {}\n",
       "    \t\"embedding_paddings\":                []\n",
       "    \t\"embedding_sizes\":                   {}\n",
       "    \t\"hidden_continuous_size\":            8\n",
       "    \t\"hidden_continuous_sizes\":           {}\n",
       "    \t\"hidden_size\":                       16\n",
       "    \t\"learning_rate\":                     0.03\n",
       "    \t\"log_gradient_flow\":                 False\n",
       "    \t\"log_interval\":                      -1\n",
       "    \t\"log_val_interval\":                  -1\n",
       "    \t\"lstm_layers\":                       1\n",
       "    \t\"max_encoder_length\":                30\n",
       "    \t\"monotone_constaints\":               {}\n",
       "    \t\"optimizer\":                         adam\n",
       "    \t\"optimizer_params\":                  None\n",
       "    \t\"output_size\":                       7\n",
       "    \t\"output_transformer\":                GroupNormalizer(\n",
       "    \t\tmethod='standard',\n",
       "    \t\tgroups=['geo_encoded', 'noc_desc_encoded', 'job_char_encoded'],\n",
       "    \t\tcenter=True,\n",
       "    \t\tscale_by_group=False,\n",
       "    \t\ttransformation=None,\n",
       "    \t\tmethod_kwargs={}\n",
       "    \t)\n",
       "    \t\"reduce_on_plateau_min_lr\":          1e-05\n",
       "    \t\"reduce_on_plateau_patience\":        1000\n",
       "    \t\"reduce_on_plateau_reduction\":       2.0\n",
       "    \t\"share_single_variable_networks\":    False\n",
       "    \t\"static_categoricals\":               []\n",
       "    \t\"static_reals\":                      ['encoder_length', 'total_vacancies_scaled_center', 'total_vacancies_scaled_scale']\n",
       "    \t\"time_varying_categoricals_decoder\": []\n",
       "    \t\"time_varying_categoricals_encoder\": []\n",
       "    \t\"time_varying_reals_decoder\":        ['relative_time_idx']\n",
       "    \t\"time_varying_reals_encoder\":        ['relative_time_idx', 'total_vacancies_scaled']\n",
       "    \t\"weight_decay\":                      0.0\n",
       "    \t\"x_categoricals\":                    []\n",
       "    \t\"x_reals\":                           ['encoder_length', 'total_vacancies_scaled_center', 'total_vacancies_scaled_scale', 'relative_time_idx', 'total_vacancies_scaled']\n",
       "    (loss): QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98])\n",
       "    (logging_metrics): ModuleList(\n",
       "      (0): SMAPE()\n",
       "      (1): MAE()\n",
       "      (2): RMSE()\n",
       "      (3): MAPE()\n",
       "    )\n",
       "    (input_embeddings): MultiEmbedding(\n",
       "      (embeddings): ModuleDict()\n",
       "    )\n",
       "    (prescalers): ModuleDict(\n",
       "      (encoder_length): Linear(in_features=1, out_features=8, bias=True)\n",
       "      (total_vacancies_scaled_center): Linear(in_features=1, out_features=8, bias=True)\n",
       "      (total_vacancies_scaled_scale): Linear(in_features=1, out_features=8, bias=True)\n",
       "      (relative_time_idx): Linear(in_features=1, out_features=8, bias=True)\n",
       "      (total_vacancies_scaled): Linear(in_features=1, out_features=8, bias=True)\n",
       "    )\n",
       "    (static_variable_selection): VariableSelectionNetwork(\n",
       "      (flattened_grn): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=24, out_features=3, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=3, out_features=3, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=3, out_features=6, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (single_variable_grns): ModuleDict(\n",
       "        (encoder_length): GatedResidualNetwork(\n",
       "          (resample_norm): ResampleNorm(\n",
       "            (resample): TimeDistributedInterpolation()\n",
       "            (gate): Sigmoid()\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (total_vacancies_scaled_center): GatedResidualNetwork(\n",
       "          (resample_norm): ResampleNorm(\n",
       "            (resample): TimeDistributedInterpolation()\n",
       "            (gate): Sigmoid()\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (total_vacancies_scaled_scale): GatedResidualNetwork(\n",
       "          (resample_norm): ResampleNorm(\n",
       "            (resample): TimeDistributedInterpolation()\n",
       "            (gate): Sigmoid()\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (prescalers): ModuleDict(\n",
       "        (encoder_length): Linear(in_features=1, out_features=8, bias=True)\n",
       "        (total_vacancies_scaled_center): Linear(in_features=1, out_features=8, bias=True)\n",
       "        (total_vacancies_scaled_scale): Linear(in_features=1, out_features=8, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (encoder_variable_selection): VariableSelectionNetwork(\n",
       "      (flattened_grn): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=2, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (context): Linear(in_features=16, out_features=2, bias=False)\n",
       "        (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=2, out_features=4, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (single_variable_grns): ModuleDict(\n",
       "        (relative_time_idx): GatedResidualNetwork(\n",
       "          (resample_norm): ResampleNorm(\n",
       "            (resample): TimeDistributedInterpolation()\n",
       "            (gate): Sigmoid()\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (total_vacancies_scaled): GatedResidualNetwork(\n",
       "          (resample_norm): ResampleNorm(\n",
       "            (resample): TimeDistributedInterpolation()\n",
       "            (gate): Sigmoid()\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (prescalers): ModuleDict(\n",
       "        (relative_time_idx): Linear(in_features=1, out_features=8, bias=True)\n",
       "        (total_vacancies_scaled): Linear(in_features=1, out_features=8, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (decoder_variable_selection): VariableSelectionNetwork(\n",
       "      (single_variable_grns): ModuleDict(\n",
       "        (relative_time_idx): GatedResidualNetwork(\n",
       "          (resample_norm): ResampleNorm(\n",
       "            (resample): TimeDistributedInterpolation()\n",
       "            (gate): Sigmoid()\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (prescalers): ModuleDict(\n",
       "        (relative_time_idx): Linear(in_features=1, out_features=8, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (static_context_variable_selection): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (static_context_initial_hidden_lstm): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (static_context_initial_cell_lstm): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (static_context_enrichment): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lstm_encoder): LSTM(16, 16, batch_first=True)\n",
       "    (lstm_decoder): LSTM(16, 16, batch_first=True)\n",
       "    (post_lstm_gate_encoder): GatedLinearUnit(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "    )\n",
       "    (post_lstm_gate_decoder): GatedLinearUnit(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "    )\n",
       "    (post_lstm_add_norm_encoder): AddNorm(\n",
       "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (post_lstm_add_norm_decoder): AddNorm(\n",
       "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (static_enrichment): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (context): Linear(in_features=16, out_features=16, bias=False)\n",
       "      (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (multihead_attn): InterpretableMultiHeadAttention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (v_layer): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (q_layers): ModuleList(\n",
       "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (k_layers): ModuleList(\n",
       "        (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (softmax): Softmax(dim=2)\n",
       "      )\n",
       "      (w_h): Linear(in_features=16, out_features=16, bias=False)\n",
       "    )\n",
       "    (post_attn_gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (pos_wise_ff): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_output_gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (output_layer): Linear(in_features=16, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "tft_module = TFTModule(tft)  # Recreate the TFTModule\n",
    "tft_module.load_state_dict(torch.load(\"tft_model_job_char.pth\"))\n",
    "tft_module.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare future data for prediction\n",
    "future_time_idx = range(expanded_data['time_idx'].max() + 1, expanded_data['time_idx'].max() + 121)\n",
    "future_data = []\n",
    "\n",
    "for geo in aggregated_data['geo_encoded'].unique():\n",
    "    for sector in aggregated_data['noc_desc_encoded'].unique():\n",
    "        for job_char in aggregated_data['job_char_encoded'].unique():\n",
    "            for time_idx in future_time_idx:\n",
    "                future_data.append([time_idx, geo, sector, job_char,None])\n",
    "\n",
    "future_df = pd.DataFrame(\n",
    "    future_data,\n",
    "    columns=['time_idx', 'geo_encoded', 'noc_desc_encoded', 'job_char_encoded' ,'total_vacancies_scaled']\n",
    ")\n",
    "future_df['total_vacancies_scaled'] = 0  # Placeholder for predictions\n",
    "\n",
    "# Ensure unique index for combined data\n",
    "combined_data = pd.concat([expanded_data, future_df]).drop_duplicates(subset=['time_idx', 'geo_encoded', 'noc_desc_encoded','job_char_encoded'])\n",
    "combined_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Ensure consistent data types\n",
    "combined_data[\"geo_encoded\"] = combined_data[\"geo_encoded\"].astype(int)\n",
    "combined_data[\"noc_desc_encoded\"] = combined_data[\"noc_desc_encoded\"].astype(int)\n",
    "combined_data[\"job_char_encoded\"] = combined_data[\"job_char_encoded\"].astype(int)\n",
    "\n",
    "combined_dataset = TimeSeriesDataSet.from_dataset(train_dataset, combined_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing columns with default values to future_df\n",
    "future_df['ref_date'] = pd.NaT  # Use NaT (Not a Timestamp) for datetime columns\n",
    "future_df['geo'] = \"Unknown\"  # Default string value\n",
    "future_df['noc_desc'] = \"Unknown\"  # Default string value\n",
    "future_df['total_vacancies'] = 0  # Default numeric value\n",
    "future_df['job_char'] = \"Unknown\"  # Default string value\n",
    "# Determine the starting date from expanded_data (if available)\n",
    "start_date = pd.to_datetime(expanded_data['ref_date'].min())  # Adjust as necessary\n",
    "\n",
    "# Populate ref_date in future_df based on time_idx\n",
    "future_df['ref_date'] = future_df['time_idx'].apply(lambda idx: start_date + pd.Timedelta(days=idx))\n",
    "\n",
    "# Combine expanded_data and updated future_df\n",
    "combined_data = pd.concat([expanded_data, future_df]).drop_duplicates(subset=['time_idx', 'geo_encoded', 'noc_desc_encoded', 'job_char_encoded'])\n",
    "combined_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1255098, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " geo_encoded               0\n",
      "noc_desc_encoded          0\n",
      "job_char_encoded          0\n",
      "time_idx                  0\n",
      "ref_date                  0\n",
      "geo                       0\n",
      "noc_desc                  0\n",
      "job_char                  0\n",
      "total_vacancies           0\n",
      "total_vacancies_scaled    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = combined_data.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_18676\\2057770027.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data['total_vacancies_scaled'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "combined_data['total_vacancies_scaled'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_encoded                       object\n",
      "noc_desc_encoded                  object\n",
      "job_char_encoded                  object\n",
      "time_idx                           int64\n",
      "ref_date                  datetime64[ns]\n",
      "geo                               object\n",
      "noc_desc                          object\n",
      "job_char                          object\n",
      "total_vacancies                  float64\n",
      "total_vacancies_scaled           float64\n",
      "dtype: object\n",
      "Index(['geo_encoded', 'noc_desc_encoded', 'job_char_encoded', 'time_idx',\n",
      "       'ref_date', 'geo', 'noc_desc', 'job_char', 'total_vacancies',\n",
      "       'total_vacancies_scaled'],\n",
      "      dtype='object')\n",
      "(1255098, 10)\n"
     ]
    }
   ],
   "source": [
    "# Check for None or NaN values\n",
    "assert combined_data.isnull().sum().sum() == 0, \"Dataset contains missing values.\"\n",
    "\n",
    "# Inspect for unexpected data types\n",
    "print(combined_data.dtypes)\n",
    "\n",
    "# Ensure combined_data contains expected columns and no empty rows\n",
    "print(combined_data.columns)\n",
    "print(combined_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(combined_dataset)):\n",
    "#     print(f\"Index {i}: {combined_dataset[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_encoded               0\n",
      "noc_desc_encoded          0\n",
      "job_char_encoded          0\n",
      "time_idx                  0\n",
      "ref_date                  0\n",
      "geo                       0\n",
      "noc_desc                  0\n",
      "job_char                  0\n",
      "total_vacancies           0\n",
      "total_vacancies_scaled    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "combined_data['geo_encoded'] = combined_data['geo_encoded'].astype(str)\n",
    "combined_data['noc_desc_encoded'] = combined_data['noc_desc_encoded'].astype(str)\n",
    "combined_data['job_char_encoded'] = combined_data['job_char_encoded'].astype(str)\n",
    "\n",
    "combined_data.fillna(0, inplace=True)  # Replace NaN with 0\n",
    "print(combined_data.isnull().sum())    # Confirm no missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_encoded: geo_encoded\n",
      "<class 'str'>    1255098\n",
      "Name: count, dtype: int64\n",
      "noc_desc_encoded: noc_desc_encoded\n",
      "<class 'str'>    1255098\n",
      "Name: count, dtype: int64\n",
      "job_char_encoded: job_char_encoded\n",
      "<class 'str'>    1255098\n",
      "Name: count, dtype: int64\n",
      "time_idx: time_idx\n",
      "<class 'int'>    1255098\n",
      "Name: count, dtype: int64\n",
      "ref_date: ref_date\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>    1255098\n",
      "Name: count, dtype: int64\n",
      "geo: geo\n",
      "<class 'str'>    1255098\n",
      "Name: count, dtype: int64\n",
      "noc_desc: noc_desc\n",
      "<class 'str'>    1255098\n",
      "Name: count, dtype: int64\n",
      "job_char: job_char\n",
      "<class 'str'>    1255098\n",
      "Name: count, dtype: int64\n",
      "total_vacancies: total_vacancies\n",
      "<class 'float'>    1255098\n",
      "Name: count, dtype: int64\n",
      "total_vacancies_scaled: total_vacancies_scaled\n",
      "<class 'float'>    1255098\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in combined_data.columns:\n",
    "    print(f\"{column}: {combined_data[column].apply(type).value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Combined Data Length: 1255098\n"
     ]
    }
   ],
   "source": [
    "# Confirm that combined_data is not empty\n",
    "print(f\"Filtered Combined Data Length: {len(combined_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index after filtering\n",
    "combined_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['time_idx', 'total_vacancies_scaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify your numerical and categorical columns\n",
    "numerical_cols = ['time_idx', 'total_vacancies_scaled']  # replace with your actual numerical column names\n",
    "categorical_cols = ['geo_encoded', 'noc_desc_encoded', 'job_char_encoded']  # replace with your actual categorical column names\n",
    "\n",
    "# Fill missing values in numerical columns with 0\n",
    "combined_data[numerical_cols] = combined_data[numerical_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_encoded</th>\n",
       "      <th>noc_desc_encoded</th>\n",
       "      <th>job_char_encoded</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>ref_date</th>\n",
       "      <th>geo</th>\n",
       "      <th>noc_desc</th>\n",
       "      <th>job_char</th>\n",
       "      <th>total_vacancies</th>\n",
       "      <th>total_vacancies_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>0.004558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>0.004558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>0.004558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>0.004127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>0.004127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255093</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3406</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255094</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3407</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255095</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255096</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3409</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255097</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3410</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255098 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        geo_encoded noc_desc_encoded job_char_encoded  time_idx   ref_date  \\\n",
       "0                 0                0                0         3 2015-01-04   \n",
       "1                 0                0                0         4 2015-01-04   \n",
       "2                 0                0                0         5 2015-01-04   \n",
       "3                 0                0                0         6 2015-01-07   \n",
       "4                 0                0                0         7 2015-01-07   \n",
       "...             ...              ...              ...       ...        ...   \n",
       "1255093          13                2                1      3406 2024-04-29   \n",
       "1255094          13                2                1      3407 2024-04-30   \n",
       "1255095          13                2                1      3408 2024-05-01   \n",
       "1255096          13                2                1      3409 2024-05-02   \n",
       "1255097          13                2                1      3410 2024-05-03   \n",
       "\n",
       "             geo                                          noc_desc   job_char  \\\n",
       "0        Alberta  Business, finance and administration occupations  Full-time   \n",
       "1        Alberta  Business, finance and administration occupations  Full-time   \n",
       "2        Alberta  Business, finance and administration occupations  Full-time   \n",
       "3        Alberta  Business, finance and administration occupations  Full-time   \n",
       "4        Alberta  Business, finance and administration occupations  Full-time   \n",
       "...          ...                                               ...        ...   \n",
       "1255093  Unknown                                           Unknown    Unknown   \n",
       "1255094  Unknown                                           Unknown    Unknown   \n",
       "1255095  Unknown                                           Unknown    Unknown   \n",
       "1255096  Unknown                                           Unknown    Unknown   \n",
       "1255097  Unknown                                           Unknown    Unknown   \n",
       "\n",
       "         total_vacancies  total_vacancies_scaled  \n",
       "0                 4705.0                0.004558  \n",
       "1                 4705.0                0.004558  \n",
       "2                 4705.0                0.004558  \n",
       "3                 4260.0                0.004127  \n",
       "4                 4260.0                0.004127  \n",
       "...                  ...                     ...  \n",
       "1255093              0.0                0.000000  \n",
       "1255094              0.0                0.000000  \n",
       "1255095              0.0                0.000000  \n",
       "1255096              0.0                0.000000  \n",
       "1255097              0.0                0.000000  \n",
       "\n",
       "[1255098 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: ({'x_cat': tensor([], size=(90, 0), dtype=torch.int64), 'x_cont': tensor([[ 1.0000, -0.1683, -0.1865, -1.0000, -0.1814],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.9667, -0.1814],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.9333, -0.1814],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.9000, -0.3560],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.8667, -0.3560],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.8333, -0.3560],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.8000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.7667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.7333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.7000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.6667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.6333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.6000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.5667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.5333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.5000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.4667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.4333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.4000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.3667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.3333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.3000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.2667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.2333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.2000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.1667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.1333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.1000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.0667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865, -0.0333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.0000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.0333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.0667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.1000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.1333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.1667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.2000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.2333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.2667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.3000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.3333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.3667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.4000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.4333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.4667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.5000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.5333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.5667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.6000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.6333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.6667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.7000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.7333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.7667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.8000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.8333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.8667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.9000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.9333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  0.9667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.0000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.0333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.0667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.1000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.1333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.1667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.2000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.2333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.2667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.3000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.3333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.3667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.4000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.4333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.4667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.5000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.5333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.5667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.6000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.6333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.6667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.7000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.7333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.7667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.8000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.8333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.8667, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.9000, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.9333, -0.6522],\n",
      "        [ 1.0000, -0.1683, -0.1865,  1.9667, -0.6522]]), 'encoder_length': 30, 'decoder_length': 60, 'encoder_target': tensor([0.0046, 0.0046, 0.0046, 0.0041, 0.0041, 0.0041, 0.0034, 0.0034, 0.0034,\n",
      "        0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
      "        0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
      "        0.0034, 0.0034, 0.0034]), 'encoder_time_idx_start': tensor(3), 'groups': tensor([0, 0, 0]), 'target_scale': array([0.00500613, 0.00246926])}, (tensor([0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
      "        0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
      "        0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
      "        0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
      "        0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
      "        0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
      "        0.0034, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034]), None))\n"
     ]
    }
   ],
   "source": [
    "# Inspect the structure of an item in combined_dataset\n",
    "for item in combined_dataset:\n",
    "    print(f\"Item: {item}\")\n",
    "    break  # Inspect just the first item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_encoded               0\n",
      "noc_desc_encoded          0\n",
      "job_char_encoded          0\n",
      "time_idx                  0\n",
      "ref_date                  0\n",
      "geo                       0\n",
      "noc_desc                  0\n",
      "job_char                  0\n",
      "total_vacancies           0\n",
      "total_vacancies_scaled    0\n",
      "dtype: int64\n",
      "  geo_encoded noc_desc_encoded job_char_encoded  time_idx   ref_date      geo  \\\n",
      "0           0                0                0         3 2015-01-04  Alberta   \n",
      "1           0                0                0         4 2015-01-04  Alberta   \n",
      "2           0                0                0         5 2015-01-04  Alberta   \n",
      "3           0                0                0         6 2015-01-07  Alberta   \n",
      "4           0                0                0         7 2015-01-07  Alberta   \n",
      "\n",
      "                                           noc_desc   job_char  \\\n",
      "0  Business, finance and administration occupations  Full-time   \n",
      "1  Business, finance and administration occupations  Full-time   \n",
      "2  Business, finance and administration occupations  Full-time   \n",
      "3  Business, finance and administration occupations  Full-time   \n",
      "4  Business, finance and administration occupations  Full-time   \n",
      "\n",
      "   total_vacancies  total_vacancies_scaled  \n",
      "0           4705.0                0.004558  \n",
      "1           4705.0                0.004558  \n",
      "2           4705.0                0.004558  \n",
      "3           4260.0                0.004127  \n",
      "4           4260.0                0.004127  \n"
     ]
    }
   ],
   "source": [
    "# Validate combined_data\n",
    "combined_data.fillna(0, inplace=True)  # Replace missing values\n",
    "print(combined_data.isnull().sum())   # Confirm no missing values\n",
    "print(combined_data.head())           # Preview dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(combined_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesDataSet[length=1224380](\n",
       "\ttime_idx='time_idx',\n",
       "\ttarget='total_vacancies_scaled',\n",
       "\tgroup_ids=['geo_encoded', 'noc_desc_encoded', 'job_char_encoded'],\n",
       "\tweight=None,\n",
       "\tmax_encoder_length=30,\n",
       "\tmin_encoder_length=15,\n",
       "\tmin_prediction_idx=0,\n",
       "\tmin_prediction_length=60,\n",
       "\tmax_prediction_length=60,\n",
       "\tstatic_categoricals=None,\n",
       "\tstatic_reals=None,\n",
       "\ttime_varying_known_categoricals=None,\n",
       "\ttime_varying_known_reals=None,\n",
       "\ttime_varying_unknown_categoricals=None,\n",
       "\ttime_varying_unknown_reals=['total_vacancies_scaled'],\n",
       "\tvariable_groups=None,\n",
       "\tconstant_fill_strategy=None,\n",
       "\tallow_missing_timesteps=True,\n",
       "\tlags=None,\n",
       "\tadd_relative_time_idx=True,\n",
       "\tadd_target_scales=True,\n",
       "\tadd_encoder_length=True,\n",
       "\ttarget_normalizer=GroupNormalizer(\n",
       "\tmethod='standard',\n",
       "\tgroups=['geo_encoded', 'noc_desc_encoded', 'job_char_encoded'],\n",
       "\tcenter=True,\n",
       "\tscale_by_group=False,\n",
       "\ttransformation=None,\n",
       "\tmethod_kwargs={}\n",
       "),\n",
       "\tcategorical_encoders={'geo_encoded': NaNLabelEncoder(add_nan=False, warn=True), 'noc_desc_encoded': NaNLabelEncoder(add_nan=False, warn=True), 'job_char_encoded': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__geo_encoded': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__noc_desc_encoded': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__job_char_encoded': NaNLabelEncoder(add_nan=False, warn=True)},\n",
       "\tscalers={'encoder_length': StandardScaler(), 'total_vacancies_scaled_center': StandardScaler(), 'total_vacancies_scaled_scale': StandardScaler(), 'relative_time_idx': StandardScaler()},\n",
       "\trandomize_length=None,\n",
       "\tpredict_mode=False\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_encoded               0\n",
      "noc_desc_encoded          0\n",
      "job_char_encoded          0\n",
      "time_idx                  0\n",
      "ref_date                  0\n",
      "geo                       0\n",
      "noc_desc                  0\n",
      "job_char                  0\n",
      "total_vacancies           0\n",
      "total_vacancies_scaled    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_encoded</th>\n",
       "      <th>noc_desc_encoded</th>\n",
       "      <th>job_char_encoded</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>ref_date</th>\n",
       "      <th>geo</th>\n",
       "      <th>noc_desc</th>\n",
       "      <th>job_char</th>\n",
       "      <th>total_vacancies</th>\n",
       "      <th>total_vacancies_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249632</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1962</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Occupations in art, culture, recreation and sport</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>5790.0</td>\n",
       "      <td>0.005609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675618</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2752</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>Occupations in education, law and social, comm...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>0.002015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350963</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2482</td>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Occupations in art, culture, recreation and sport</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202393</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2582</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>86635.0</td>\n",
       "      <td>0.083931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186639</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2282</td>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Total, all occupations</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73219</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1258</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Sales and service occupations</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>8260.0</td>\n",
       "      <td>0.008002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317361</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>652</td>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Health occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459395</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2057</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>Occupations in manufacturing and utilities</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075642</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1208</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Natural resources, agriculture and related pro...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977101</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1317</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Natural resources, agriculture and related pro...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>2315.0</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239932 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geo_encoded  noc_desc_encoded  job_char_encoded  time_idx   ref_date  \\\n",
       "249632             2                 5                 0      1962 2020-01-10   \n",
       "675618             7                 6                 2      2752 2022-01-10   \n",
       "350963             3                 5                 0      2482 2021-01-10   \n",
       "202393             2                 0                 0      2582 2022-01-10   \n",
       "1186639           13                 9                 1      2282 2021-01-10   \n",
       "...              ...               ...               ...       ...        ...   \n",
       "73219              0                 8                 1      1258 2018-01-10   \n",
       "317361             3                 1                 0       652 2016-01-10   \n",
       "459395             4                 7                 0      2057 2020-01-10   \n",
       "1075642           12                 4                 0      1208 2018-01-10   \n",
       "977101            11                 4                 2      1317 2018-01-10   \n",
       "\n",
       "                   geo                                           noc_desc  \\\n",
       "249632          Canada  Occupations in art, culture, recreation and sport   \n",
       "675618     Nova Scotia  Occupations in education, law and social, comm...   \n",
       "350963        Manitoba  Occupations in art, culture, recreation and sport   \n",
       "202393          Canada   Business, finance and administration occupations   \n",
       "1186639          Yukon                             Total, all occupations   \n",
       "...                ...                                                ...   \n",
       "73219          Alberta                      Sales and service occupations   \n",
       "317361        Manitoba                                 Health occupations   \n",
       "459395   New Brunswick         Occupations in manufacturing and utilities   \n",
       "1075642   Saskatchewan  Natural resources, agriculture and related pro...   \n",
       "977101          Quebec  Natural resources, agriculture and related pro...   \n",
       "\n",
       "                        job_char  total_vacancies  total_vacancies_scaled  \n",
       "249632                 Full-time           5790.0                0.005609  \n",
       "675618   Type of work, all types           2080.0                0.002015  \n",
       "350963                 Full-time            310.0                0.000300  \n",
       "202393                 Full-time          86635.0                0.083931  \n",
       "1186639                Part-time            270.0                0.000262  \n",
       "...                          ...              ...                     ...  \n",
       "73219                  Part-time           8260.0                0.008002  \n",
       "317361                 Full-time            585.0                0.000567  \n",
       "459395                 Full-time           1755.0                0.001700  \n",
       "1075642                Full-time            505.0                0.000489  \n",
       "977101   Type of work, all types           2315.0                0.002243  \n",
       "\n",
       "[239932 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify missing values\n",
    "print(val_df.isnull().sum())\n",
    "\n",
    "# Drop or fill missing values\n",
    "test_df = val_df.fillna(0)  # Replace missing values with 0 or another strategy\n",
    "\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = [item for item in combined_dataset if item is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save it to a file\n",
    "# with open(\"combined_dataset_job_char.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(combined_dataset, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump\n",
    "# dump(combined_dataset, \"combined_dataset_job_char.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import pickle\n",
    "\n",
    "# # # Load the dataset\n",
    "# # with open(\"combined_dataset_job_char.pkl\", \"rb\") as file:\n",
    "# #     combined_dataset = pickle.load(file)\n",
    "\n",
    "# from joblib import load\n",
    "\n",
    "# # Load the joblib file\n",
    "# combined_dataset = load(\"combined_dataset_job_char.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesDataSet[length=1224380](\n",
       "\ttime_idx='time_idx',\n",
       "\ttarget='total_vacancies_scaled',\n",
       "\tgroup_ids=['geo_encoded', 'noc_desc_encoded', 'job_char_encoded'],\n",
       "\tweight=None,\n",
       "\tmax_encoder_length=30,\n",
       "\tmin_encoder_length=15,\n",
       "\tmin_prediction_idx=0,\n",
       "\tmin_prediction_length=60,\n",
       "\tmax_prediction_length=60,\n",
       "\tstatic_categoricals=None,\n",
       "\tstatic_reals=None,\n",
       "\ttime_varying_known_categoricals=None,\n",
       "\ttime_varying_known_reals=None,\n",
       "\ttime_varying_unknown_categoricals=None,\n",
       "\ttime_varying_unknown_reals=['total_vacancies_scaled'],\n",
       "\tvariable_groups=None,\n",
       "\tconstant_fill_strategy=None,\n",
       "\tallow_missing_timesteps=True,\n",
       "\tlags=None,\n",
       "\tadd_relative_time_idx=True,\n",
       "\tadd_target_scales=True,\n",
       "\tadd_encoder_length=True,\n",
       "\ttarget_normalizer=GroupNormalizer(\n",
       "\tmethod='standard',\n",
       "\tgroups=['geo_encoded', 'noc_desc_encoded', 'job_char_encoded'],\n",
       "\tcenter=True,\n",
       "\tscale_by_group=False,\n",
       "\ttransformation=None,\n",
       "\tmethod_kwargs={}\n",
       "),\n",
       "\tcategorical_encoders={'geo_encoded': NaNLabelEncoder(add_nan=False, warn=True), 'noc_desc_encoded': NaNLabelEncoder(add_nan=False, warn=True), 'job_char_encoded': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__geo_encoded': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__noc_desc_encoded': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__job_char_encoded': NaNLabelEncoder(add_nan=False, warn=True)},\n",
       "\tscalers={'encoder_length': StandardScaler(), 'total_vacancies_scaled_center': StandardScaler(), 'total_vacancies_scaled_scale': StandardScaler(), 'relative_time_idx': StandardScaler()},\n",
       "\trandomize_length=None,\n",
       "\tpredict_mode=False\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate combined_dataset as a TimeSeriesDataSet\n",
    "combined_dataset = TimeSeriesDataSet.from_dataset(\n",
    "\ttrain_dataset, \n",
    "\tcombined_data,\n",
    "\tcategorical_encoders={\n",
    "\t\t\"geo_encoded\": NaNLabelEncoder(add_nan=True),\n",
    "\t\t\"noc_desc_encoded\": NaNLabelEncoder(add_nan=True),\n",
    "        \"job_char_encoded\": NaNLabelEncoder(add_nan=True)\n",
    "        \n",
    "\t}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoader\n",
    "dataloader = combined_dataset.to_dataloader(train=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1ed0ba8e870>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_encoded</th>\n",
       "      <th>noc_desc_encoded</th>\n",
       "      <th>job_char_encoded</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>ref_date</th>\n",
       "      <th>geo</th>\n",
       "      <th>noc_desc</th>\n",
       "      <th>job_char</th>\n",
       "      <th>total_vacancies</th>\n",
       "      <th>total_vacancies_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249632</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1962</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Occupations in art, culture, recreation and sport</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>5790.0</td>\n",
       "      <td>0.005609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675618</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2752</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>Occupations in education, law and social, comm...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>0.002015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350963</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2482</td>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Occupations in art, culture, recreation and sport</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202393</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2582</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>86635.0</td>\n",
       "      <td>0.083931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186639</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2282</td>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Total, all occupations</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73219</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1258</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Sales and service occupations</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>8260.0</td>\n",
       "      <td>0.008002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317361</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>652</td>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Health occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459395</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2057</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>Occupations in manufacturing and utilities</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075642</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1208</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Natural resources, agriculture and related pro...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977101</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1317</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Natural resources, agriculture and related pro...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>2315.0</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239932 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geo_encoded  noc_desc_encoded  job_char_encoded  time_idx   ref_date  \\\n",
       "249632             2                 5                 0      1962 2020-01-10   \n",
       "675618             7                 6                 2      2752 2022-01-10   \n",
       "350963             3                 5                 0      2482 2021-01-10   \n",
       "202393             2                 0                 0      2582 2022-01-10   \n",
       "1186639           13                 9                 1      2282 2021-01-10   \n",
       "...              ...               ...               ...       ...        ...   \n",
       "73219              0                 8                 1      1258 2018-01-10   \n",
       "317361             3                 1                 0       652 2016-01-10   \n",
       "459395             4                 7                 0      2057 2020-01-10   \n",
       "1075642           12                 4                 0      1208 2018-01-10   \n",
       "977101            11                 4                 2      1317 2018-01-10   \n",
       "\n",
       "                   geo                                           noc_desc  \\\n",
       "249632          Canada  Occupations in art, culture, recreation and sport   \n",
       "675618     Nova Scotia  Occupations in education, law and social, comm...   \n",
       "350963        Manitoba  Occupations in art, culture, recreation and sport   \n",
       "202393          Canada   Business, finance and administration occupations   \n",
       "1186639          Yukon                             Total, all occupations   \n",
       "...                ...                                                ...   \n",
       "73219          Alberta                      Sales and service occupations   \n",
       "317361        Manitoba                                 Health occupations   \n",
       "459395   New Brunswick         Occupations in manufacturing and utilities   \n",
       "1075642   Saskatchewan  Natural resources, agriculture and related pro...   \n",
       "977101          Quebec  Natural resources, agriculture and related pro...   \n",
       "\n",
       "                        job_char  total_vacancies  total_vacancies_scaled  \n",
       "249632                 Full-time           5790.0                0.005609  \n",
       "675618   Type of work, all types           2080.0                0.002015  \n",
       "350963                 Full-time            310.0                0.000300  \n",
       "202393                 Full-time          86635.0                0.083931  \n",
       "1186639                Part-time            270.0                0.000262  \n",
       "...                          ...              ...                     ...  \n",
       "73219                  Part-time           8260.0                0.008002  \n",
       "317361                 Full-time            585.0                0.000567  \n",
       "459395                 Full-time           1755.0                0.001700  \n",
       "1075642                Full-time            505.0                0.000489  \n",
       "977101   Type of work, all types           2315.0                0.002243  \n",
       "\n",
       "[239932 rows x 10 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save it to a file\n",
    "# with open(\"dataloader.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(dataloader, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the joblib file\n",
    "dataloader = load(\"dataloader.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0050,  0.0050,  0.0050,  ...,  0.0050,  0.0050,  0.0050],\n",
      "        [ 0.0050,  0.0050,  0.0050,  ...,  0.0050,  0.0050,  0.0050],\n",
      "        [ 0.0050,  0.0050,  0.0050,  ...,  0.0050,  0.0050,  0.0050],\n",
      "        ...,\n",
      "        [-0.0006, -0.0004, -0.0006,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [-0.0006, -0.0004, -0.0006,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [-0.0006, -0.0004, -0.0006,  ..., -0.0005, -0.0005, -0.0005]])\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = tft.predict(dataloader, return_x=False)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save predictions to a file\n",
    "with open(\"predictions_job_char.pkl\", \"wb\") as file:\n",
    "    pickle.dump(predictions, file)\n",
    "\n",
    "# from joblib import dump\n",
    "# dump(predictions, \"predictions_job_char.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Load predictions from a file\n",
    "# with open(\"predictions.pkl\", \"rb\") as file:\n",
    "#     predictions = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1224380, 60])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions Shape: torch.Size([1224380, 60])\n",
      "Future DF Length: 55440\n",
      "Unique Geo Encoded: 14\n",
      "Unique NOC Desc Encoded: 11\n",
      "Unique Job Char Encoded: 3\n",
      "Future predictions saved to 'future_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Check the unique values and lengths\n",
    "print(f\"Predictions Shape: {predictions.shape}\")\n",
    "print(f\"Future DF Length: {len(future_df)}\")\n",
    "print(f\"Unique Geo Encoded: {future_df['geo_encoded'].nunique()}\")\n",
    "print(f\"Unique NOC Desc Encoded: {future_df['noc_desc_encoded'].nunique()}\")\n",
    "print(f\"Unique Job Char Encoded: {future_df['job_char_encoded'].nunique()}\")\n",
    "\n",
    "future_df\n",
    "future_df.to_csv(\"future_predictions.csv\", index=False)\n",
    "print(\"Future predictions saved to 'future_predictions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ref_date      geo                                           noc_desc  \\\n",
      "0    2022-04-01   Quebec                             Total, all occupations   \n",
      "1    2022-07-01   Quebec                             Total, all occupations   \n",
      "2    2022-10-01   Quebec                             Total, all occupations   \n",
      "3    2023-01-01   Quebec                             Total, all occupations   \n",
      "4    2023-04-01   Quebec                             Total, all occupations   \n",
      "...         ...      ...                                                ...   \n",
      "9175 2026-01-01  Alberta  Natural and applied sciences and related occup...   \n",
      "9176 2026-04-01  Alberta  Natural and applied sciences and related occup...   \n",
      "9177 2026-07-01  Alberta  Natural and applied sciences and related occup...   \n",
      "9178 2026-10-01  Alberta  Natural and applied sciences and related occup...   \n",
      "9179 2027-01-01  Alberta  Natural and applied sciences and related occup...   \n",
      "\n",
      "      predicted_vacancies                 job_char  scaled_vacancies  \n",
      "0                0.005001                Full-time                 0  \n",
      "1                0.005001                Full-time                 0  \n",
      "2                0.004959                Full-time                 0  \n",
      "3                0.004984                Full-time                 0  \n",
      "4                0.004968                Full-time                 0  \n",
      "...                   ...                      ...               ...  \n",
      "9175             0.004984  Type of work, all types                 0  \n",
      "9176             0.004984  Type of work, all types                 0  \n",
      "9177             0.004984  Type of work, all types                 0  \n",
      "9178             0.004984  Type of work, all types                 0  \n",
      "9179             0.004984  Type of work, all types                 0  \n",
      "\n",
      "[4800 rows x 6 columns]\n",
      "       ref_date      geo                                           noc_desc  \\\n",
      "0    2022-04-01   Quebec                             Total, all occupations   \n",
      "1    2022-07-01   Quebec                             Total, all occupations   \n",
      "2    2022-10-01   Quebec                             Total, all occupations   \n",
      "3    2023-01-01   Quebec                             Total, all occupations   \n",
      "4    2023-04-01   Quebec                             Total, all occupations   \n",
      "...         ...      ...                                                ...   \n",
      "9135 2026-01-01  Alberta  Natural and applied sciences and related occup...   \n",
      "9136 2026-04-01  Alberta  Natural and applied sciences and related occup...   \n",
      "9137 2026-07-01  Alberta  Natural and applied sciences and related occup...   \n",
      "9138 2026-10-01  Alberta  Natural and applied sciences and related occup...   \n",
      "9139 2027-01-01  Alberta  Natural and applied sciences and related occup...   \n",
      "\n",
      "      predicted_vacancies                 job_char  scaled_vacancies  \n",
      "0                0.005001                Full-time                 0  \n",
      "1                0.005001                Full-time                 0  \n",
      "2                0.004959                Full-time                 0  \n",
      "3                0.004984                Full-time                 0  \n",
      "4                0.004968                Full-time                 0  \n",
      "...                   ...                      ...               ...  \n",
      "9135             0.004976  Type of work, all types                 0  \n",
      "9136             0.004977  Type of work, all types                 0  \n",
      "9137             0.004976  Type of work, all types                 0  \n",
      "9138             0.004977  Type of work, all types                 0  \n",
      "9139             0.004976  Type of work, all types                 0  \n",
      "\n",
      "[1540 rows x 6 columns]\n",
      "Denormalized predictions saved to 'denormalized_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save results\n",
    "future_dates = pd.date_range(start='2022-04-01', periods=20, freq='QS')  # Generate quarterly start dates\n",
    "\n",
    "# Ensure the lengths of the arrays match\n",
    "geo = geo_encoder.inverse_transform(future_df['geo_encoded'])\n",
    "noc_desc = sector_encoder.inverse_transform(future_df['noc_desc_encoded'])\n",
    "job_char = job_char_encoder.inverse_transform(future_df['job_char_encoded'])\n",
    "scaled_vacancies = future_df['total_vacancies_scaled']\n",
    "\n",
    "predicted_vacancies = predictions.flatten()\n",
    "\n",
    "# Calculate the number of unique combinations of geo, noc_desc, and job_char\n",
    "num_combinations = len(geo_encoder.classes_) * len(sector_encoder.classes_) * len(job_char_encoder.classes_)\n",
    "\n",
    "# Ensure the lengths of the arrays match\n",
    "num_predictions = len(predicted_vacancies)\n",
    "geo = geo[:num_predictions]\n",
    "noc_desc = noc_desc[:num_predictions]\n",
    "job_char = job_char[:num_predictions]\n",
    "scaled_vacancies = scaled_vacancies[:num_predictions]\n",
    "future_dates = np.tile(future_dates, num_combinations)[:num_predictions]\n",
    "\n",
    "# Ensure all arrays have the same length\n",
    "min_length = min(len(future_dates), len(geo), len(noc_desc), len(predicted_vacancies))\n",
    "future_dates = future_dates[:min_length]\n",
    "geo = geo[:min_length]\n",
    "noc_desc = noc_desc[:min_length]\n",
    "job_char = job_char[:min_length]\n",
    "scaled_vacancies = scaled_vacancies[:min_length]\n",
    "predicted_vacancies = predicted_vacancies[:min_length]\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"ref_date\": future_dates,\n",
    "    \"geo\": geo,\n",
    "    \"noc_desc\": noc_desc,\n",
    "    \"predicted_vacancies\": predicted_vacancies,\n",
    "    \"job_char\": job_char,\n",
    "    \"scaled_vacancies\": scaled_vacancies\n",
    "})\n",
    "\n",
    "# Remove duplicate rows\n",
    "results.drop_duplicates(inplace=True)\n",
    "\n",
    "print(results)\n",
    "# Remove rows with duplicates except for 'predicted_vacancies'\n",
    "results = results.loc[results.drop(columns=['predicted_vacancies']).drop_duplicates().index]\n",
    "\n",
    "print(results)\n",
    "# Denormalize the predicted vacancies\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(expanded_data[['total_vacancies']])  # Fit the scaler on the original data\n",
    "\n",
    "# Inverse transform the predicted vacancies\n",
    "results['predicted_vacancies'] = scaler.inverse_transform(results[['predicted_vacancies']])\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv(\"denormalized_predictions.csv\", index=False)\n",
    "print(\"Denormalized predictions saved to 'denormalized_predictions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'scaler' is the MinMaxScaler used for normalization\n",
    "# predicted_vacancies = predictions.flatten().reshape(-1, 1)  # Reshape predictions to match scaler's expected input\n",
    "# denormalized_vacancies = scaler.inverse_transform(predicted_vacancies)\n",
    "\n",
    "# # Convert to a DataFrame for better readability\n",
    "# denormalized_vacancies_df = pd.DataFrame(denormalized_vacancies, columns=[\"denormalized_vacancies\"])\n",
    "\n",
    "# # Display the denormalized vacancies\n",
    "# print(denormalized_vacancies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo\n",
      "Quebec          660\n",
      "Saskatchewan    660\n",
      "Alberta         220\n",
      "Name: count, dtype: int64\n",
      "noc_desc\n",
      "Total, all occupations                                                         180\n",
      "Business, finance and administration occupations                               180\n",
      "Health occupations                                                             180\n",
      "Natural and applied sciences and related occupations                           160\n",
      "Natural resources, agriculture and related production occupations              120\n",
      "Occupations in art, culture, recreation and sport                              120\n",
      "Occupations in education, law and social, community and government services    120\n",
      "Occupations in manufacturing and utilities                                     120\n",
      "Sales and service occupations                                                  120\n",
      "Trades, transport and equipment operators and related occupations              120\n",
      "Legislative and senior management occupations                                  120\n",
      "Name: count, dtype: int64\n",
      "    ref_date     geo                noc_desc  predicted_vacancies   job_char  \\\n",
      "0 2022-04-01  Quebec  Total, all occupations             0.005001  Full-time   \n",
      "1 2022-07-01  Quebec  Total, all occupations             0.005001  Full-time   \n",
      "2 2022-10-01  Quebec  Total, all occupations             0.004959  Full-time   \n",
      "3 2023-01-01  Quebec  Total, all occupations             0.004984  Full-time   \n",
      "4 2023-04-01  Quebec  Total, all occupations             0.004968  Full-time   \n",
      "\n",
      "   scaled_vacancies  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n"
     ]
    }
   ],
   "source": [
    "print(results['geo'].value_counts())  # Should show all provinces\n",
    "print(results['noc_desc'].value_counts())  # Should show all sectors\n",
    "print(results.head())  # Preview of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predicted_job_vacancies_2025_to_2035.csv'.\n"
     ]
    }
   ],
   "source": [
    "results.to_csv(\"C:/Users/sanja/OneDrive/Desktop/nor.csv\", index=False)\n",
    "print(\"Predictions saved to 'predicted_job_vacancies_2025_to_2035.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Length of combined_dataset: {len(combined_dataset)}\")\n",
    "# print(combined_dataset[0])  # Verify what data it returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare combined dataset\n",
    "# combined_dataset = TimeSeriesDataSet.from_dataset(dataset, combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions\n",
    "# predictions, _ = tft.predict(DataLoader(combined_dataset, batch_size=batch_size), return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inverse scale the predictions\n",
    "# predictions = scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save predictions to CSV\n",
    "# future_dates = pd.date_range(start='2025-01-01', periods=120, freq='M')\n",
    "# results = pd.DataFrame({\n",
    "#     \"ref_date\": future_dates,\n",
    "#     \"geo\": geo_encoder.inverse_transform(future_df['geo_encoded']),\n",
    "#     \"noc_desc\": sector_encoder.inverse_transform(future_df['noc_desc_encoded']),\n",
    "#     \"predicted_vacancies\": predictions.flatten()\n",
    "# })\n",
    "# results.to_csv(\"predicted_job_vacancies_2025_to_2035.csv\", index=False)\n",
    "\n",
    "# print(\"Predictions saved to 'predicted_job_vacancies_2025_to_2035.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
